## Chapter 25、Techniques for reducing avoidable bias

**减少可避免偏差的方法**

如果你的学习算法遭受高可避免偏差，你可以尝试以下方法：

- **增加模型大小**（如神经元/层的数量）：该方法可以减少偏差，因为它可以让你更好的适应训练集。如果你发现该方法增加了方差，那么使用正则化方法，它通常能够消除方差的增加。
- **基于错误分析的洞察修改输入特征**：假设错误分析启发你去创建额外的特征，以帮助算法消除特定类别的错误。（我们在下一章节进一步讨论）这些新特征可能有助于减少偏差和方差。理论上来说，增加更多的特征可能会增加方差，但如果你发现这种情况，那么久使用正则化方法，它通常能够消除方差的增加。
- **减少或消除正则化**（L2正则化，L1正则化，dropout）：这将减少可避免偏差，但会增加方差。
- **修改模型架构**（如神经网络架构）以便更适合你的问题：这种方法能够影响偏差和方差。

一种没有帮助的方法：

- **增加更多训练数据**：这种方法有助于解决方差问题，但是它通常对偏差没有显著的影响。