##Chapter 36、When you should train and test on different distributions

**何时应该在不同的分布下训练和测试**

你的猫图app用户已经上传了1W张图片，手动标注过是否包含猫。你还有一个更大的数据集，包含20W从互联网下载下来的图片。你该如何定义训练/开发/测试集？

由于这1W张用户图片密切地反映了你想要做好的数据实际的概率分布，你可以使用它们作为开发和测试集。如果你在训练一个数据饥渴的深度学习算法，可以给算法额外的20W互联网图片用于训练。因此，你的训练和开发/测试集来自不同的概率分布。这对工作有什么影响？

我们可以将这21W图片随机挪到训练/开发/测试集中去，而不是将数据分割成训练/开发/测试集。这种情况下，所有的数据来自相同的分布。但我建议不用这种方法，因为约 205000/2100000 = 97.6%的开发/测试数据可能来自互联网图片，这不能反映你想要做好的实际分布。记住在选择开发/测试集上我们的推荐：

选择开发测试集以反映你期望在未来获取并想做的更好的数据。

大多数机器学习上的学术文献都假定训练集、开发集和测试集都来自相同的分布【1】。在机器学习的早期，数据不足。我们通常只一些概率分布中获取一个数据集。所以我们会将数据随机切分为训练/开发/测试集，并且所有数据来自同一个来源假设通常都是满足的。

但在大数据时代，我们现在能够访问到大量的训练集，例如猫互联网图片。即使训练集和来自和开发/测试集不同的分布，我们仍希望将其用于学习，因为它能提供很多信息。

对于猫检测器例子，我们可以将用户上传的5000张图片，而不是所有的1W张放入开发/测试集中。我们可以将剩余的5000张用户上传的样例放入训练集。这样，你的205000大小的训练集中包含一些来自开发/测试分布的数据，以及20W互联网图片。我们将在下一章中讨论为什么该方法有用。

我们来看第二个例子。假设你正在构建一个语音识别系统，来转录语音控制的移动地图/导航app的街道地址。你有2W个用户讲街道地址的样例。但你也有50W用户谈论其他话题的音频剪辑。你可以将那1W个街道地址的样例作为开发/测试集，并使用剩下的1W，附加50W样例，用于训练。

我们将继续假设你的卡发数据和测试数据来自相同的分布。但重要的是，要明白不同的训练和开发/测试分布提供了一些特殊的挑战。

————————

【1】有一些关于训练和测试在不同分布上的学术研究。包括“domain adaptation”,"tarnsfer learning"和"multitask learning"。但理论和实践还是存在很大的差距。如果你在数据集A上训练，并在其上测试分布大不相同的数据B，运气会对你的算法执行效率产生巨大的影响。（这里的“运气”包含研究者对特定任务手动设计的功能，以及其他我们尚不了解的因素）这使得对不同分布上训练和测试的学术研究系统的进行比较困难。

