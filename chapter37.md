## Chapter 37、How to decide whether to use all your data

**如何决定是否使用所有数据**

假设你的猫检测器的训练集包含1W张用户上传的图片。这些数据与独立的开发/测试集来自相同的分布，代表你关心并想做好的分布。你还有额外的2W从互联网下载的图片。你应该将所有的2W+1W=3W图片提供给学习算法作为它的训练集吗？还是丢弃这2W张互联网图片，怕它偏差学习算法？

当使用前几代的学习算法时（例如手工设计的计算机视觉特征，加上一个简单的线性分类器），合并两种类型的数据确实会造成算法表现糟糕的风险。因此，一些工程师会告诫你不要包含那2W张互联网图片。

但在现代强大灵活的学习算法（例如大型神经网络）下，该风险大大降低。如果你有能力构建一个拥有足够数量的隐藏单元/层的神经网络，你可以安全地将这2W张图片加入训练集中。添加这些图片更有可能提升你的表现。

该观察依赖于一个事实，就是有一些x->y的映射在两种类型的数据上都的能很好的工作。换句话说，存在某个系统，不论你输入互联网图片还是移动app端图片都能得到可靠的预测标签，甚至不需要知道图片的来源。

添加额外的2W图片有如下影响：

1. 它给你的神经网络提供更多的猫长啥样和不长啥样的样例。这很有帮助，因为互联网图片和用户上传的移动端app图片都共享一些相似之处。神经网络可以将从互联网图片获取到的知识应用到移动app图像上。
2. 它迫使神经网络花费一些能力来学习互联网图片特定的属性（例如高分辨率，图片框架下的不同分布，等等）。如果这些特性和移动app图片大不相同，它将消耗掉神经网络的一些代表性能力。因此从移动app图片分布中识别数据的能力较低，这才是你真正关心的。理论上来说，这可能会伤害到你算法的性能。

为了用不同的术语来描述第二种影响，我们可以转向虚拟人物福尔摩斯，他说你的大脑像阁楼；它只有有限数量的空间。他说“对于每一个新增的知识，你会忘记之前记得的东西。所以，最重要的是，不要用无用的事实去排挤有用的事实”【2】。

幸运的是，如果你有构建一个大的神经网络的能力（即一个大的阁楼），那么这并不是一个严重的问题。你有足够的能力去从互联网和移动app图像上学习，而不需要两种类型的数据竞争容量。算法的“大脑”足够大以至于你不必担心阁楼空间用完。

但是如果你没有足够大的神经网络（或另一个高度灵活的学习算法），那么你应该更多的关注和你的开发/测试集分布相匹配的训练数据。

如果你认为数据无用，出于计算原因，你应该忽略这些数据。例如，假设你的开发/测试集主要包含人物、地点、地标和动物图片。假设你也有大量的扫描历史文档：

![37-0](http://oow6unnib.bkt.clouddn.com/myl-c37-0.jpg)

这些文档不包含任何类似猫的东西。它们看起来也完全不像你的开发/测试分布。将这些数据作为负样本没有任何意义，因为上面第一个影响的好处可以忽略不计，你的神经网络几乎没有什么能从这些数据中学到它可以应用到你的开发/测试集分布。包含他们会浪费神经网络的计算资源和表示能力。

————————

【2】A Study in Scarlet   by Arthur Conan Doyle  